# extraction audio avec stacher

Emmanuel Macron Discours
https://www.youtube.com/watch?v=Dm27NwstXcY


# dÃ©coupage avec Adobe Audition

![informations de durÃ©e](./img/image.png)

# Google Colab Training

https://github.com/JackismyShephard/ultimate-rvc

## Rappel des processeurs

Processeur (CPU) : calcul gÃ©nÃ©ral. OK pour prÃ©-traitement, petites tÃ¢ches, pas pour lâ€™entraÃ®nement GPU/TPU.

GPU T4 (NVIDIA, â€œTuringâ€) : entrÃ©e de gamme. 16 Go de VRAM typiquement. Bien pour inference/finetune lÃ©gers (petits LLM, diffusion en 512Â²).

GPU L4 (NVIDIA, â€œAdaâ€ datacenter) : milieu de gamme rÃ©cent, orientÃ© infÃ©rence et multimÃ©dia (NVENC/NVDEC costauds). Plus rapide que T4, VRAM typiquement 24 Go.

GPU A100 (NVIDIA, â€œAmpereâ€) : haut de gamme entraÃ®nement. TrÃ¨s rapide en FP16/BF16/TF32, beaucoup de VRAM (souvent 40 Go sur Colab). IdÃ©al pour gros batchs, gros modÃ¨les.

TPU v5e-1 (Google) : bon rapport perf/â‚¬ pour JAX/TF. TrÃ¨s efficace en BF16, mais PyTorch nÃ©cessite XLA (moins plug-and-play). â€œ-1â€ = plus petit slice.

TPU v6e-1 (Google) : gÃ©nÃ©ration plus rÃ©cente que v5e, meilleure perf/efficacitÃ© sur JAX/TF. MÃªme remarques cÃ´tÃ© PyTorch/XLA.

##  Ultimate_rvc_colab.ipynb

![Interface principale](./img/image-1.png)
![step1](./img/image-2.png)
![step2](./img/image-3.png)
![step3](./img/image-4.png)
![algorithmic](./img/image-5.png)
![datastorage](./img/image-6.png)
![Device and memory](./img/image-7.png)

### reco chatGPT5

DonnÃ©es : vise â‰¥ 10â€“15 min (mieux : 30â€“60 min) de voix propre, sans musique/bruit.

Avec 20â€“60 min de donnÃ©es : ~200â€“400 epochs suffisent gÃ©nÃ©ralement (on arrÃªte quand la val loss stagne et que lâ€™overfit apparaÃ®t).

Avec 3,7 min (ton cas) : tu peux pousser Ã  600â€“1 200 epochs pour â€œfaire sortir un timbreâ€, mais tu auras vite de lâ€™overfit (robotisation/artefacts) et la qualitÃ© restera limitÃ©e. Mieux vaut augmenter le dataset que dâ€™augmenter encore les epochs.

### Feature Extraction

F0 Method
- mvpe
- crepe
- crepe-tiny

Embedder model
- contentvec
- chinese
- japanese
- corean
- custom

### Options training

- Number of epochs
- Algorithmic

- Vocoder
  - HIFI-GAN
  - MRF HIFI-GAN
  - Refine Gan

- Index algorithm
  - Auto
  - Faiss
  - KMeans
- Pretrained model type
  - Default
  - None
  - Custom


Parfait ðŸ‘ tu touches Ã  un point **clÃ© de RVC** : la mÃ©thode dâ€™extraction de la **hauteur fondamentale (F0 / pitch)**.
Cette Ã©tape est essentielle car elle dÃ©termine la justesse et la prosodie de la voix clonÃ©e.

Voici les diffÃ©rences :

---

## ðŸ”¹ F0 Method

### 1. **mvpe (Multi-view Pitch Estimation)**

* MÃ©thode plus rÃ©cente et rapide.
* Assez robuste mÃªme avec du bruit.
* Bon compromis entre prÃ©cision et vitesse.
* **RecommandÃ©** si tu veux entraÃ®ner vite sans perdre trop de qualitÃ©.

---

### 2. **crepe**

* Utilise un modÃ¨le neuronal (CREPE) spÃ©cialisÃ© dans la dÃ©tection de pitch.
* **TrÃ¨s prÃ©cis**, surtout sur des voix claires et bien enregistrÃ©es.
* Plus lent que `mvpe` car il calcule frame par frame.
* IdÃ©al si tu cherches **qualitÃ© maximale**, au prix dâ€™un temps dâ€™extraction plus long.

---

### 3. **crepe-tiny**

* Version allÃ©gÃ©e de CREPE.
* Plus rapide mais **moins prÃ©cis**, parfois instable si lâ€™enregistrement est bruitÃ© ou si la voix monte/descend vite.
* Tu peux lâ€™utiliser pour tester ou si tu as beaucoup dâ€™audio.

---

ðŸ‘‰ En rÃ©sumÃ© :

* **mvpe** â†’ rapide, fiable, recommandÃ© par dÃ©faut.
* **crepe** â†’ plus lent, mais meilleur rendu si tu veux la prÃ©cision fine du pitch (souvent meilleur pour chanter).
* **crepe-tiny** â†’ juste si tu veux gagner du temps, mais la qualitÃ© peut en souffrir.



## ðŸ”¹ 1. **Number of epochs**

* Une **epoch** = un passage complet de ton dataset (tous tes fichiers audio) dans le modÃ¨le.
* Plus dâ€™epochs â†’ meilleure convergence, mais risque dâ€™**overfitting** (le modÃ¨le â€œmÃ©moriseâ€ au lieu de gÃ©nÃ©raliser).
* Typiquement en RVC, avec ~5â€“10 minutes de voix, on est entre **200â€“400 epochs** pour un rendu correct.
* Tu peux arrÃªter avant si la `gen_loss` se stabilise.

---

## ðŸ”¹ 2. **Algorithmic**

* Ici Ã§a dÃ©signe le **mÃ©thode de calcul des features dâ€™entraÃ®nement** (par ex. extraction de pitch/F0, spectrogrammes, etc.).
* Certains notebooks appellent Ã§a "algorithmic features" ou "algorithmic training".
* En pratique, câ€™est le choix de la stratÃ©gie dâ€™extraction des **caractÃ©ristiques acoustiques** de ta voix qui seront ensuite utilisÃ©es par le modÃ¨le.
* Tu laisses souvent par dÃ©faut sauf si tu veux tester un autre pipeline dâ€™extraction.

---

## ðŸ”¹ 3. **Vocoder**

Le vocoder est la brique qui **reconstruit lâ€™audio final** Ã  partir des features intermÃ©diaires.
DiffÃ©rents vocoders donnent un rendu diffÃ©rent :

* **HiFi-GAN**

  * Le plus classique et rapide.
  * Donne un son propre et naturel dans la majoritÃ© des cas.

* **MRF HiFi-GAN** (*Multi-Receptive Field HiFi-GAN*)

  * Variante amÃ©liorÃ©e qui capte mieux les dÃ©tails fins (formants, intonations).
  * LÃ©gÃ¨rement plus lourd mais meilleure qualitÃ©.

* **Refine GAN**

  * Ã‰tape de "post-traitement" qui raffine le rendu.
  * Peut donner une meilleure clartÃ© sur certaines voix mais plus lent.

ðŸ‘‰ En rÃ©sumÃ© : **HiFi-GAN** pour vitesse, **MRF** pour qualitÃ© plus riche, **Refine GAN** si tu veux un rendu plus poli.

---

## ðŸ”¹ 4. **Index algorithm**

Câ€™est pour construire lâ€™**index de features** utilisÃ© dans la conversion par recherche (retrieval).
Cet index permet de rapprocher la voix cible des segments de ta voix entraÃ®nÃ©e.

* **Auto**

  * Laisse le systÃ¨me choisir (souvent FAISS).

* **Faiss**

  * Librairie optimisÃ©e (Facebook AI Similarity Search).
  * Rapide et efficace pour la recherche de voisins.

* **KMeans**

  * Regroupe les features en clusters.
  * Moins prÃ©cis mais parfois plus stable si ton dataset est petit.

ðŸ‘‰ En gÃ©nÃ©ral : **FAISS** est le plus utilisÃ©/recommandÃ©.

---

## ðŸ”¹ 5. **Pretrained model type**

DÃ©termine si tu pars dâ€™un modÃ¨le dÃ©jÃ  entraÃ®nÃ© ou pas.

* **Default**

  * Utilise le modÃ¨le prÃ©-entraÃ®nÃ© RVC fourni par dÃ©faut.
  * Câ€™est la meilleure option si tu nâ€™as que peu de donnÃ©es (il sert de base et apprend juste ta voix).

* **None**

  * EntraÃ®ne Ã  partir de zÃ©ro, sans prÃ©-apprentissage.
  * Plus long, nÃ©cessite beaucoup de donnÃ©es (plusieurs heures de voix).

* **Custom**

  * Tu donnes ton propre modÃ¨le de dÃ©part (par ex. un autre `.pth` que tu as dÃ©jÃ ).
  * Utile si tu veux affiner un modÃ¨le existant ou entraÃ®ner une variante.

---

ðŸ‘‰ Donc, en rÃ©sumÃ©, les rÃ©glages conseillÃ©s pour un premier essai avec tes **8 minutes 22 secondes de dataset** :

* **Epochs** : 250â€“400
* **Algorithmic** : Default (ne touche pas si tu ne sais pas)
* **Vocoder** : HiFi-GAN ou MRF HiFi-GAN si tu veux plus de dÃ©tails
* **Index algorithm** : FAISS
* **Pretrained model type** : Default

## Output

.pth = poids du modÃ¨le (obligatoire).

.index = index de features (optionnel mais recommandÃ© : meilleure stabilitÃ©/timbre quand tu rÃ¨gles un â€œindex rateâ€ > 0).

![pitch extraction](image.png)

